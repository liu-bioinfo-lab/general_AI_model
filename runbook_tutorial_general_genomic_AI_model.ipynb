{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6fyjicu+WYlfNpGBM4TPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liu-bioinfo-lab/general_AI_model/blob/main/runbook_tutorial_general_genomic_AI_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please open Google Colab notebook under TPU/GPU setting : **Runtime -> Change runtime type**"
      ],
      "metadata": {
        "id": "D5qpZqD-RGg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWdYeHm1J31w",
        "outputId": "c54a1286-de5b-444f-cf67-8c073d62ad9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'general_AI_model'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 118 (delta 1), reused 0 (delta 0), pack-reused 111 (from 2)\u001b[K\n",
            "Receiving objects: 100% (118/118), 68.61 MiB | 14.27 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Updating files: 100% (92/92), done.\n",
            "/content/general_AI_model/general_AI_model\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/liu-bioinfo-lab/general_AI_model.git\n",
        "%cd general_AI_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "from src.model import build_model\n",
        "import argparse\n",
        "import torch\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "!pip install kipoiseq==0.5.2 --quiet > /dev/null\n",
        "import kipoiseq\n",
        "from kipoiseq import Interval\n",
        "import pyfaidx\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "DgYhJxG-Kq_D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Model**"
      ],
      "metadata": {
        "id": "auzsboB1NfQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "model_path = 'models/ckpt.pt'\n",
        "gdown.download('https://drive.google.com/uc?id=1aTpGvAUkvaxsDP_isA2n2Udbfqa9walW', model_path, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "nZGmMdViMR2I",
        "outputId": "373295f7-6ccc-4dfb-910e-88acff924d5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1aTpGvAUkvaxsDP_isA2n2Udbfqa9walW\n",
            "From (redirected): https://drive.google.com/uc?id=1aTpGvAUkvaxsDP_isA2n2Udbfqa9walW&confirm=t&uuid=f97b15e6-4895-48d4-9e0e-3cdf99af8a8e\n",
            "To: /content/general_AI_model/general_AI_model/models/ckpt.pt\n",
            "100%|██████████| 468M/468M [00:06<00:00, 68.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'models/ckpt.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### The following codes are copied from https://github.com/deepmind/deepmind-research/blob/master/enformer/enformer-usage.ipynb\n",
        "fasta_file = '/root/data/genome.fa'\n",
        "!mkdir -p /root/data\n",
        "!wget -O - http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz | gunzip -c > {fasta_file}\n",
        "pyfaidx.Faidx(fasta_file)\n",
        "!ls /root/data\n",
        "class FastaStringExtractor:\n",
        "    def __init__(self, fasta_file):\n",
        "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
        "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
        "\n",
        "    def extract(self, interval: Interval, **kwargs) -> str:\n",
        "        # Truncate interval if it extends beyond the chromosome lengths.\n",
        "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
        "        trimmed_interval = Interval(interval.chrom,\n",
        "                                    max(interval.start, 0),\n",
        "                                    min(interval.end, chromosome_length),\n",
        "                                    )\n",
        "        # pyfaidx wants a 1-based interval\n",
        "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
        "                                          trimmed_interval.start + 1,\n",
        "                                          trimmed_interval.stop).seq).upper()\n",
        "        # Fill truncated values with N's.\n",
        "        pad_upstream = 'N' * max(-interval.start, 0)\n",
        "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
        "        return pad_upstream + sequence + pad_downstream\n",
        "\n",
        "    def close(self):\n",
        "        return self.fasta.close()\n",
        "fasta_extractor = FastaStringExtractor(fasta_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wUTlH9Y0LO",
        "outputId": "b96597a3-d797-4ae3-d144-c6521535b1fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-09 03:56:50--  http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
            "Resolving hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 983659424 (938M) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 938.09M  25.9MB/s    in 41s     \n",
            "\n",
            "2025-06-09 03:57:32 (22.8 MB/s) - written to stdout [983659424/983659424]\n",
            "\n",
            "genome.fa  genome.fa.fai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a downsampled GM12878 ATAC-seq for example\n",
        "os.makedirs('tmp_save', exist_ok=True)\n",
        "atac_path = 'tmp_save/GM12878_ATAC.pickle'\n",
        "gdown.download('https://drive.google.com/uc?id=1ua-fQHYjPH658oEKEpIaDBHNFbzsO1m0', atac_path, quiet=False)\n",
        "with open(atac_path, 'rb') as f:\n",
        "    atac_data = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PP1IKWSZeu4",
        "outputId": "36a0d463-ef99-4a97-9ca8-653633119ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ua-fQHYjPH658oEKEpIaDBHNFbzsO1m0\n",
            "From (redirected): https://drive.google.com/uc?id=1ua-fQHYjPH658oEKEpIaDBHNFbzsO1m0&confirm=t&uuid=7b2894df-0fc9-4536-b375-3ce531b701cd\n",
            "To: /content/general_AI_model/general_AI_model/tmp_save/GM12878_ATAC.pickle\n",
            "100%|██████████| 192M/192M [00:01<00:00, 119MB/s]\n",
            "<ipython-input-10-32c361593af3>:6: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  atac_data = pickle.load(f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(sequence):\n",
        "    return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
        "def pad_seq_matrix(matrix, pad_left, pad_right, pad_len=300):\n",
        "    # add flanking region to each sample\n",
        "    dmatrix = np.concatenate((pad_left, matrix[:, :, -pad_len:]), axis=0)[:-1, :, :]\n",
        "    umatrix = np.concatenate((matrix[:, :, :pad_len], pad_right), axis=0)[1:, :, :]\n",
        "    return np.concatenate((dmatrix, matrix, umatrix), axis=2)\n",
        "\n",
        "def pad_signal_matrix(matrix,pad_dnase_left,pad_dnase_right, pad_len=300):\n",
        "    dmatrix = np.vstack((pad_dnase_left, matrix[:, -pad_len:]))[:-1, :]\n",
        "    umatrix = np.vstack((matrix[:, :pad_len], pad_dnase_right))[1:, :]\n",
        "    return np.hstack((dmatrix, matrix, umatrix))\n",
        "\n",
        "\n",
        "def prepare_input(\n",
        "    fasta_extractor,\n",
        "    chrom, start, end,\n",
        "    atac_data\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate the inputs to the model\n",
        "    Args:\n",
        "        fasta_extractor (kipoiseq.extractors.FastaStringExtractor): kipoiseq.extractors.FastaStringExtractor object\n",
        "        chrom (str), start (int), end (int): Specify a genomic region (chromosome, start genomic position, and end genomic position),\n",
        "                and the size of the genomic region should be divisible by 1000.\n",
        "        dnase (ndarray): a numpy array representing DNase-seq signals in the same chromosome\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: a torch tensor (N x 5 x 1600) representing input genomic sequences and DNase-seq, where N represents the number of\n",
        "                1kb sequences in the input genomic region\n",
        "    \"\"\"\n",
        "    assert end - start == 500000\n",
        "\n",
        "    start = start - 50000\n",
        "    end = end + 50000\n",
        "\n",
        "    if isinstance(chrom, str):\n",
        "        try:\n",
        "            chrom_atac = int(chrom.replace('chr',''))\n",
        "        except Exception:\n",
        "            chrom_atac = chrom.replace('chr','')\n",
        "    else:\n",
        "        chrom_atac = chrom\n",
        "\n",
        "    if start>=end:\n",
        "        raise ValueError('the start of genomic region should be small than the end.')\n",
        "    if start < 300 or end+300 > atac_data[chrom_atac].shape[-1]:\n",
        "        raise ValueError('please leave enough flanking region.')\n",
        "\n",
        "    target_interval = kipoiseq.Interval(chrom, start, end)\n",
        "    sequence_one_hot = one_hot_encode(fasta_extractor.extract(target_interval))\n",
        "    sequence_matrix = sequence_one_hot.reshape(-1, 1000, 4).swapaxes(1, 2)\n",
        "\n",
        "    pad_interval = kipoiseq.Interval(chrom, start - 300, start)\n",
        "    seq_pad_left = np.expand_dims(one_hot_encode(fasta_extractor.extract(pad_interval)).swapaxes(0, 1), 0)\n",
        "    pad_interval = kipoiseq.Interval(chrom, end, end + 300)\n",
        "    seq_pad_right = np.expand_dims(one_hot_encode(fasta_extractor.extract(pad_interval)).swapaxes(0, 1), 0)\n",
        "    seq_input = pad_seq_matrix(sequence_matrix, seq_pad_left, seq_pad_right)\n",
        "\n",
        "\n",
        "    pad_atac_left=atac_data[chrom_atac][:,start-300:start].toarray().squeeze(0)\n",
        "    pad_atac_right = atac_data[chrom_atac][:,end:end+300].toarray().squeeze(0)\n",
        "    center_atac = atac_data[chrom_atac][:,start:end].toarray().squeeze(0).reshape(-1, 1000)\n",
        "\n",
        "    atac_input = np.expand_dims(pad_signal_matrix(center_atac ,pad_atac_left,pad_atac_right), 1)\n",
        "\n",
        "    inputs = torch.tensor(np.concatenate((seq_input, atac_input), axis=1)).float()\n",
        "    return inputs.unsqueeze(0)\n",
        "\n",
        "\n",
        "def extract_outputs(outputs):\n",
        "    rep_1d, rep_2d, outs, extra_outs = [x.cpu().detach().numpy() for x in outputs]\n",
        "\n",
        "    output_dict = {}\n",
        "    output_dict['1D rep'] = rep_1d\n",
        "    output_dict['2D rep'] = rep_2d\n",
        "\n",
        "    modalities=['epi', 'rna', 'bru', 'microc', 'hic','intact_hic','rna_strand',\n",
        "                'extra_tf', 'tt', 'groseq', 'grocap', 'proseq','netcage','starr']\n",
        "    for i, d in enumerate(outs + extra_outs):\n",
        "        output_dict[modalities[i]] = d\n",
        "\n",
        "    return output_dict\n"
      ],
      "metadata": {
        "id": "FoBCcTw0aHI0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parser_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--bins', type=int, default=600)\n",
        "    parser.add_argument('--crop', type=int, default=50)\n",
        "    parser.add_argument('--embed_dim', default=960, type=int)\n",
        "    args = parser.parse_args([])\n",
        "    return args\n",
        "\n",
        "def get_args():\n",
        "    args = parser_args()\n",
        "    return args\n",
        "\n",
        "args = get_args()\n",
        "\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "    device = xm.xla_device()\n",
        "else:\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = build_model(args)\n",
        "model.load_state_dict(torch.load(model_path, map_location='cpu'),strict=True)\n",
        "model.eval()\n",
        "model.to(device)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF1WQNSQNL6O",
        "outputId": "f1ef6120-22f6-449d-b710-ccbb7bf6d1bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify an interested region\n",
        "\n",
        "chrom, start, end = ['chr1', 1500000, 2000000]\n",
        "\n",
        "input_x = prepare_input(\n",
        "    fasta_extractor,\n",
        "    chrom, start, end,\n",
        "    atac_data\n",
        ").to(device)\n",
        "\n",
        "rep_1d, rep_2d, outputs, external_outputs = model(input_x,return_rep=True)"
      ],
      "metadata": {
        "id": "E7OOCIXQR37c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rep_1d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_uN8JH4dzWq",
        "outputId": "708f7536-914d-4ddf-fe33-597477ad71ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 600, 960])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99Uavd6IfB9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}